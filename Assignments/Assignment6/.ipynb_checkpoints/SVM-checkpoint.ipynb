{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Support Vector Machine from Scratch in Python\n",
    "\n",
    "Support Vector Machine (SVM) is a popular classification algorithm. Here we implement the algorithm for binary classification problems (i.e., there are two classes only). A toy dataset of six observations with two input variables is used to test the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smsize = 6\n",
    "features = 2\n",
    "x = np.array([[1,7], [2,8], [3,8],\n",
    "             [5,1], [6,-1], [7,3]])\n",
    "# positive class: y = 1; negative class: y = -1\n",
    "y = np.array([-1, -1, -1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a scatter plot\n",
    "fig = plt.figure(figsize = (10, 5))   \n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i in range(smsize):\n",
    "    if y[i] == 1:\n",
    "        ax.plot(x[i,0], x[i,1], 'o', color='r')\n",
    "    else:\n",
    "        ax.plot(x[i,0], x[i,1], 'X', color='g')\n",
    "# Linear SVM\n",
    "clf = LinearSVC()\n",
    "clf.fit(x, y)\n",
    "w = np.array(clf.coef_).reshape(2,)\n",
    "b = clf.intercept_\n",
    "ax.text(3, 3, '%+.4fx1%+.4fx2%+4.2f=0' %(w[0], w[1], b))\n",
    "w = w/(-1*w[1])\n",
    "b /= -1*w[1]\n",
    "x2 = np.linspace(0, 7, 15)\n",
    "y2 = np.dot(x2, w[0]) + b\n",
    "ax.plot(x2, y2, 'b-')\n",
    "# configuring the plot\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_title('Support Vector Machine')\n",
    "ax.set_ylim(-2, 10)\n",
    "# ax.text(3, 3, '%+.4fx1%+.4fx2%+4.2f=0' %(w[0], w[1], b))\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Machine - Two Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_history = []\n",
    "loss_history = []\n",
    "# learning rate\n",
    "lr = 1.0e-2\n",
    "# margin\n",
    "delta = 1.0\n",
    "# initialization\n",
    "B = 0.0\n",
    "W = np.ones(x.shape[1]) * 1.0e-3\n",
    "for t in range(100):\n",
    "    score = np.dot(x, W) + B\n",
    "    z = delta - y * score\n",
    "    loss = np.sum(z[z > 0])/smsize\n",
    "    para_history.append((W, B))\n",
    "    loss_history.append(loss)\n",
    "    # gradient descent\n",
    "    sign = z > 0\n",
    "    B += lr * np.sum(sign * y) / smsize\n",
    "    W += lr * np.dot(sign * y, x) / smsize\n",
    "print('Loss = %.4f' %loss)\n",
    "print(\"B=%.4f\" %B)\n",
    "print(\"W[0]=%.4f\" %W[0])\n",
    "print(\"W[1]=%.4f\" %W[1])\n",
    "for i in range(100):\n",
    "    if (i+1) % 1 == 0:\n",
    "        print(\"Iteration %3d: Loss = %.4f\" %(i+1, loss_history[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
