{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, Preparation and Visualization: A Tutorial\n",
    "\n",
    "- Data Preparation\n",
    "    - Data loading\n",
    "    - Data cleaning\n",
    "    - Data transforming\n",
    "- Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data\n",
    "\n",
    "- pandas features a number of functions for reading tabular data as a DataFrame object.\n",
    "    - read_csv\n",
    "    - read_excel\n",
    "    - read_json\n",
    "    - read_sql\n",
    "\n",
    "- DataFrame has methods to write data to a file.\n",
    "    - to_csv\n",
    "    - to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data in Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a csv file\n",
    "!cat students.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a csv file\n",
    "df = pd.read_csv('students.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the index\n",
    "df2 = pd.read_csv('students.csv', index_col = 'Fname')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a csv file without a header row\n",
    "!cat students2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas assigns default column names\n",
    "df3 = pd.read_csv('students2.csv', header = None)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify column names\n",
    "df4 = pd.read_csv('students2.csv', names = ['Fname', 'Gender', 'Major', 'GPA'])\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a text file where fields are separated by a variable amount of whitespace\n",
    "!cat students3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the text file using a regular expression as a delimiter\n",
    "df5 = pd.read_csv('students3.txt', sep = '\\s+')\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a csv file with missing values\n",
    "!cat students4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read a file with missing values\n",
    "df6 = pd.read_csv('students4.csv')\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Data to Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data out to a csv file\n",
    "df7 = pd.read_csv('students.csv')\n",
    "# to_csv is a DataFrame's method\n",
    "df7.to_csv('out.csv', index = False, header = False)\n",
    "!cat out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a subset of the columns\n",
    "df7.to_csv('out2.csv', index = False, columns = ['Fname', 'GPA'])\n",
    "!cat out2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Data\n",
    "\n",
    "- JSON has become one of the standard formats for sending data by HTTP request between web browsers and other applications.\n",
    "- JSON is close to valid Python code. \n",
    "- Basic types: objects (dicts), arrays (lists), strings, numbers, booleans, and nulls.\n",
    "- All of the keys in an JSON object must be strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a JSON string\n",
    "obj = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"Name\": \"Mike\",\n",
    "        \"Gender\": \"M\", \n",
    "        \"Major\": \"FIN\",\n",
    "        \"GPA\": 3.4\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"Mary\",\n",
    "        \"Gender\": \"F\", \n",
    "        \"Major\": \"MGT\",\n",
    "        \"GPA\": 3.7\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"Lily\",\n",
    "        \"Gender\": \"F\", \n",
    "        \"Major\": null,\n",
    "        \"GPA\": 3.2\n",
    "    }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a JSON string to a Pyathon form\n",
    "lst = json.loads(obj)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a JSON object to a DataFrame\n",
    "df8 = DataFrame(lst, columns = ['Name', 'Major'])\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a JSON file\n",
    "!cat students5.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a JSON file\n",
    "df9 = pd.read_json('students5.json')\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to a JSON file\n",
    "df9.to_json('students6.json', orient = 'records')\n",
    "!cat students6.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert a Python object back to JSON\n",
    "lst2 = df9.to_dict(orient = 'records')\n",
    "asjson = json.dumps(lst2)\n",
    "asjson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "- Web scraping is the practice of automated gathering data from the internet.\n",
    "- This is accomplished by writing an antomated program that queries a web server, requests data, and then parses the data to extract needed information.\n",
    "- Web scraping process flow\n",
    "    - Retrieving HTML data -- **requests** library\n",
    "    - Parsing the data -- **BeautifulSoup** library and **re** module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "html = requests.get('http://postmda.github.io/MDA610/Pages/HTMLIntro.html')\n",
    "# a status code of 200 indicates that the page was downloaded successfully\n",
    "print(html.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the content of the page\n",
    "print(html.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing HTML Data\n",
    "\n",
    "- `BeautifulSoup` objects\n",
    "- `Tag` objects\n",
    "    - bs.*tagName* returns the first instance of the tag.\n",
    "    - bs.*find(tagName, tagAttributes)* returns the first instance of the tag with specified attribute values.\n",
    "    - bs.*find_all(tagName, tagAttributes)* returns a list of the tags.\n",
    "- `NavigableString` objects\n",
    "    - tag.*get_text()* returns the text within the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform HTML into a BeautifulSoup object\n",
    "bs = BeautifulSoup(html.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the content of the page with a nice format\n",
    "print(bs.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print out the title element\n",
    "print(bs.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the first paragraph\n",
    "print(bs.p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the first span element with class=attr\n",
    "print(bs.find('span', {'class': 'attr'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all instances of the 'span' tag with class=attr\n",
    "stag = bs.find_all('span', {'class': 'attr'})\n",
    "print(stag)\n",
    "for sp in stag:\n",
    "    print(sp.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find all instances with the class attribute containing 'text'\n",
    "pars = bs.find_all(class_='text')\n",
    "for element in pars:\n",
    "    print(element.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find an element by id\n",
    "bs.find(id = 'first').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating Trees\n",
    "\n",
    "- Tree navigation finds a tag based on its location in a document. \n",
    "- BeautifulSoup functions always deal with the descendants of the current tag selected.\n",
    "- tag.*children* returns the elements one level below a parent. \n",
    "- *next_sibling, *next_siblings*, *previous_sibling*, and *previous_siblings* can be applied to access the elements at the same level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descendants at different levels\n",
    "bs.body.find_all('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a list of the elements at the top level\n",
    "lst1 = list(bs.children)\n",
    "print(lst1)\n",
    "lst1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dow Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://money.cnn.com/data/dow30/')\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use BeautifulSoup to extract the ticker, name and stock price of each company\n",
    "bs4 = BeautifulSoup(page.content, 'html.parser')\n",
    "# a dictionary\n",
    "dow = {}\n",
    "# ticker and company name retrieval \n",
    "Symbols = bs4.find_all(class_ = 'wsod_firstCol')\n",
    "dow['Ticker'] = []\n",
    "dow['Company'] = []\n",
    "for s in Symbols[1:]:\n",
    "    txt = s.get_text()\n",
    "    dow['Ticker'].append(txt[:txt.find(u'\\xa0')])\n",
    "    dow['Company'].append(txt[txt.find(u'\\xa0'):].replace(u'\\xa0', u''))\n",
    "# data retrieval\n",
    "dow['Price'] = []\n",
    "Elements = bs4.find_all('span', class_ = 'wsod_stream')\n",
    "print(len(Elements))\n",
    "i = 0\n",
    "for item in Elements:\n",
    "    if i % 3 == 0:\n",
    "        dow['Price'].append(item.get_text())\n",
    "    i += 1\n",
    "DowDF = DataFrame(dow, index = dow['Ticker'])\n",
    "DowDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Regular Expressions to extract the ticker, name and stock price of each company\n",
    "import re\n",
    "pattern = r'wsod_symbol\">(.*?)</a>.*?<span.*?>(.*?)</span>.*?\\n.*?wsod_stream\">(.*?)</span>'\n",
    "dlist = re.findall(pattern, page.text)\n",
    "DowDF2 = DataFrame(dlist, columns = ['Ticker', 'Company', 'Price'])\n",
    "DowDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use BeautifulSoup to retrieve all data\n",
    "bs4 = BeautifulSoup(page.content, 'html.parser')\n",
    "# a dictionary\n",
    "dow = {}\n",
    "# ticker and company name retrieval \n",
    "Symbols = bs4.find_all(class_ = 'wsod_firstCol')\n",
    "dow['Ticker'] = []\n",
    "dow['Company'] = []\n",
    "for s in Symbols[1:]:\n",
    "    txt = s.get_text()\n",
    "    dow['Ticker'].append(txt[:txt.find(u'\\xa0')])\n",
    "    dow['Company'].append(txt[txt.find(u'\\xa0'):].replace(u'\\xa0', u''))\n",
    "# column name retrieval\n",
    "Header = bs4.find_all('th', {'class': 'wsod_aRight'})\n",
    "keys = [item.get_text() for item in Header]\n",
    "for k in keys:\n",
    "    dow[k] = []\n",
    "# data retrieval\n",
    "Data = bs4.find_all('td', class_ = 'wsod_aRight')\n",
    "i = 0\n",
    "for s in Data:\n",
    "    if i % 5 == 0 or i % 5 == 4:\n",
    "        dow[keys[i % 5]].append(s.find('span').get_text())\n",
    "    elif i % 5 == 3:\n",
    "        dow[keys[i % 5]].append(s.get_text())\n",
    "    else:\n",
    "        dow[keys[i % 5]].append(s.find('span').find('span').get_text())\n",
    "    i += 1\n",
    "dow\n",
    "dowDF3 = DataFrame(dow, index = dow['Ticker'])\n",
    "dowDF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use Regular Expressions to extract all data\n",
    "pattern_header = r'wsod_firstCol\">(.*?)</th>\\n.*?wsod_aRight\">(.*?)</th>\\n.*?wsod_aRight\">(.*?)</th>\\n.*?wsod_aRight\">(.*?)</th>\\n.*?wsod_aRight\">(.*?)</th>\\n.*?wsod_aRight\">(.*?)</th>'\n",
    "columns = re.findall(pattern_header, page.text)\n",
    "print(columns)\n",
    "clist = list(columns[0])\n",
    "clist[5] = clist[5].replace('<br>', ' ')\n",
    "clist.insert(0, 'Ticker')\n",
    "print(clist)\n",
    "pattern_data = r'wsod_symbol\">(.*?)</a>.*?<span.*?>(.*?)</span>.*?\\n.*?wsod_stream\">(.*?)</span>.*?\\n.*?Data\">(.*?)</span>.*?\\n.*?ChangePct\">(.*?)</span>.*?\\n.*?wsod_aRight\">(.*?)</td>.*?\\n.*?Data\">(.*?)</span>'\n",
    "dlist = re.findall(pattern_data, page.text)\n",
    "DowDF4 = DataFrame(dlist, columns = clist)\n",
    "DowDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    " \n",
    "- `float('nan')`, `Numpy.nan` and Python `None` value are treated as missing values in pandas. \n",
    "- `isnull()` and `notnull()` are used to detect missing values.\n",
    "- `dropna()` filters out missing data.\n",
    "- `fillna()` fills in missing data with some value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Out Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a series\n",
    "ser = Series([1, 2, np.nan, 5, np.nan])\n",
    "print(ser)\n",
    "ser.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe\n",
    "df = DataFrame([[1.0, 6.2, 3.0, 7.0], \n",
    "                [2.0, np.nan, np.nan, 8.0], \n",
    "                [np.nan, 2.0, 3.5, 0.0], \n",
    "                [np.nan, 1.0, 4.0, 2.0]], columns = list('abcd'))\n",
    "print(df)\n",
    "# dropna() by default drops any rows with missing values\n",
    "print(df.dropna())\n",
    "# dropna() drops any column with missing values\n",
    "df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing data with a constant\n",
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use different fill value for each column\n",
    "df.fillna({'a': 0, 'b': 10, 'c': 100, 'd': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the original object in place\n",
    "df2 = df.copy()\n",
    "_ = df2.fillna(0, inplace = True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values with interpolation: forward fill; backward fill\n",
    "print(df.fillna(method = 'ffill'))\n",
    "df.fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values with the mean value\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "- In a DataFrame, each column has its own data type.\n",
    "- `dtypes` property returns the data types\n",
    "- `astype()` method changes the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = DataFrame([[2, 3, 4], [5, 6, 7]], columns = list('abc'))\n",
    "print(df2.dtypes)\n",
    "# revise the data type of column 'b'\n",
    "df2 = df2.astype({'b': np.float64})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = DataFrame({'A': [1, 2], 'B':[3, 4]})\n",
    "dfb = DataFrame({'A': [0, 3]})\n",
    "dfa.add(dfb, fill_value = 0).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any value with a z-score above 3 or below -3 is an outlier\n",
    "np.random.seed(12345)\n",
    "df3 = DataFrame(np.random.randn(500, 3))\n",
    "# number of outliers\n",
    "(df3.abs() > 3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many columns have outliers?\n",
    "print((df3.abs() > 3).any().sum())\n",
    "# how many rows have outliers?\n",
    "(df3.abs() > 3).any(axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Values\n",
    "\n",
    "- `replace()` method replaces values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single value\n",
    "ser3 = Series([-1., 0.5, 0.6, -1., 0.2])\n",
    "print(ser3)\n",
    "ser3.replace(-1., np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace a list of values\n",
    "ser3[3] = -2\n",
    "ser3.replace([-1, -2], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding a Categorical Variable\n",
    "\n",
    "- Integer encoding: assign an integer to each distinct category.\n",
    "- One-hot encoding: if there are `k` categories, then define `k` dummy variables and with `one` in one variable and `0` in the other variables for each category.\n",
    "- Dummy encoding: if there are `k` categories, then define `k-1` dummy variables and with all zeros for one category, and `one` in one variable and `0` in the other variables for each of the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a Series of ordinal data\n",
    "ser4 = Series(['Good', 'Poor', 'Good', 'Excellent', 'Excellent'])\n",
    "ser4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# integer encoding\n",
    "ser5 = ser4.replace({'Poor':1, 'Good':2, 'Excellent':3})\n",
    "ser5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Series of nominal data\n",
    "ser6 = Series(['English', 'English', 'French', 'French', 'Chinese'])\n",
    "ser6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding with pandas.get_dummies() method\n",
    "df_e = pd.get_dummies(ser6)\n",
    "df_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encoding\n",
    "df_d = df_e.copy()\n",
    "del df_d['Chinese']\n",
    "df_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = DataFrame({'a': ['A', 'B'] * 3, 'b': [1, 2, 1] * 2})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .duplicated() method detects duplicates\n",
    "df3.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .drop_duplicates() method removes duplicates\n",
    "df3.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Data Using a Function or Mapping\n",
    "\n",
    "- `Series.map()` method transforms data in a column or a Series.\n",
    "- `DataFrame.apply()` method transforms data using a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = DataFrame({'Name': ['Mike', 'Mary', 'Lily'], \n",
    "                 'GPA': [2.9, 3.7, 3.5], \n",
    "                 'Major': ['MATH', 'FIN', 'EDU']})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the DataFrame\n",
    "Major_to_College = {'MATH': 'LAS', 'MGT': 'COM', 'FIN': 'COM', 'EDU': 'EDU'}\n",
    "df4['COL'] = df4.Major.map(Major_to_College)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = DataFrame(np.random.randn(12).reshape(3, 4), columns = list('abcd'))\n",
    "# normalization\n",
    "df5.apply(lambda x: (x.max() - x)/(x.max() - x.min()), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization and Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .cut() method\n",
    "grades = [98, 64, 52, 78, 90, 76, 82, 85, 81]\n",
    "bins = [50, 60, 70, 80, 90, 100]\n",
    "cats = pd.cut(grades, bins)\n",
    "print(cats)\n",
    "cats.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency distribution\n",
    "pd.value_counts(cats, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "- Matplotlib is a multiplatform data visualization library built on Numpy arrays.\n",
    "- In Jupyter notebooks, put all the plotting commands for a figure in a single notebook cell.\n",
    "- Steps to plot:\n",
    "    - Create a new figure with `fig = plt.figure()`.\n",
    "    - Add one or more subplots using `ax = fig.add_subplot()`.\n",
    "    - Call `ax.plot()` to draw the curve in each subplot.\n",
    "    - Format the appearance of the axes and lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive plotting in Jupyter notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures and Subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple line plot\n",
    "fig = plt.figure(figsize = (10, 5))   # figsize is in inches\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "x = np.linspace(0, 10, 100)\n",
    "ax.plot(x, np.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple plots\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "x = np.linspace(0, 10, 100)\n",
    "ax1.plot(x, np.sin(x))\n",
    "ax2.plot(x, np.cos(x))\n",
    "ax3.plot(x, np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors, Markers and Line Styles\n",
    "\n",
    "- Colors: 'bgrcmykw'\n",
    "- Linestyles: '-', '--', '-.', ':'\n",
    "- Markers: '.O*+xv^<>nph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a line plot with markers\n",
    "fig = plt.figure(figsize = (10, 5))   \n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "np.random.seed(12345)\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.random.randn(100)\n",
    "ax.plot(x, y, 'go--')   # green, circular markers and dashed curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a scatter plot\n",
    "fig = plt.figure(figsize = (10, 5))   \n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "np.random.seed(12345)\n",
    "x = np.linspace(0, 5, 10)\n",
    "y = 2 * x + np.random.randn(10)\n",
    "ax.plot(x, y, 'ro')   # red, circular markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a histogram\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "data = np.random.randn(1000)\n",
    "ax.hist(data, bins = 10, density = True, histtype = 'stepfilled', color = 'steelblue', edgecolor = 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axes, Title, Labels, and Legends\n",
    "- Axis limits: `ax.set_xlim()`, `ax.set_ylim()`, or `ax.set_axis()`\n",
    "- Title: `ax.set_title()`\n",
    "- Axis labels: `ax.set_xlabel()`, `ax.set_ylabel()`\n",
    "- Legends: `ax.legend()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a figure with multiple line plots\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "x = np.linspace(0, 10, 100)\n",
    "ax.plot(x, np.sin(x), label = 'six(x)')\n",
    "ax.plot(x, np.cos(x), label = 'cos(x)')\n",
    "ax.set_title('Functions of six(x) and cos(x)')\n",
    "ax.set_xlabel('x value')\n",
    "ax.set_ylabel('function')\n",
    "ax.set_xlim([0, 10])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
