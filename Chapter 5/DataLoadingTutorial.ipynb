{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Storage: A Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data\n",
    "\n",
    "- pandas features a number of functions for reading tabular data as a DataFrame object.\n",
    "    - read_csv\n",
    "    - read_excel\n",
    "    - read_json\n",
    "    - read_sql\n",
    "\n",
    "- DataFrame has methods to write data to a file.\n",
    "    - to_csv\n",
    "    - to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data in Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a csv file without a header row\n",
    "!cat students2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas assigns default column names\n",
    "df3 = pd.read_csv('students2.csv', header = None)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify column names\n",
    "df4 = pd.read_csv('students2.csv', names = ['Fname', 'Gender', 'Major', 'GPA'])\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a text file where fields are separated by a variable amount of whitespace\n",
    "!cat students3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the text file using a regular expression as a delimiter\n",
    "df5 = pd.read_csv('students3.txt', sep = '\\s+')\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a csv file with missing values\n",
    "!cat students4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read a file missing missing values\n",
    "df6 = pd.read_csv('students4.csv')\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Data to Text Format"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# write the data out to a csv file\n",
    "df7 = pd.read_csv('students.csv')\n",
    "# to_csv is a DataFrame's method\n",
    "df7.to_csv('out.csv', index = False, header = False)\n",
    "!cat out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a subset of the columns\n",
    "df7.to_csv('out2.csv', index = False, columns = ['Fname', 'GPA'])\n",
    "!cat out2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Data\n",
    "\n",
    "- JSON has become one of the standard formats for sending data by HTTP request between web browsers and other applications.\n",
    "- JSON is close to valid Python code. \n",
    "- Basic types: objects (dicts), arrays (lists), strings, numbers, booleans, and nulls.\n",
    "- All of the keys in an JSON object must be strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a JSON string\n",
    "obj = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"Name\": \"Mike\",\n",
    "        \"Gender\": \"M\", \n",
    "        \"Major\": \"FIN\",\n",
    "        \"GPA\": 3.4\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"Mary\",\n",
    "        \"Gender\": \"F\", \n",
    "        \"Major\": \"MGT\",\n",
    "        \"GPA\": 3.7\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"Lily\",\n",
    "        \"Gender\": \"F\", \n",
    "        \"Major\": null,\n",
    "        \"GPA\": 3.2\n",
    "    }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a JSON string to a Pyathon form\n",
    "lst = json.loads(obj)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a JSON object to a DataFrame\n",
    "df8 = pd.DataFrame(lst, columns = ['Name', 'Major'])\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a JSON file\n",
    "!cat students5.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a JSON file\n",
    "df9 = pd.read_json('students5.json')\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to a JSON file\n",
    "df9.to_json('students6.json', orient = 'records')\n",
    "!cat students6.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a Python object back to JSON\n",
    "lst2 = df9.to_dict(orient = 'records')\n",
    "asjson = json.dumps(lst2)\n",
    "asjson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "- Web scraping is the practice of automated gathering data from the internet.\n",
    "- This is accomplished by writing an antomated program that queries a web server, requests data, and then parses the data to extract needed information.\n",
    "- Web scraping process flow\n",
    "    - Retrieving HTML data -- **requests** library\n",
    "    - Parsing the data -- **BeautifulSoup** library and **re** module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "html = requests.get('http://dataquestio.github.io/web-scraping-pages/simple.html')\n",
    "# a status code of 200 indicates that the page was downloaded successfully\n",
    "print(html.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the content of the page\n",
    "print(html.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing HTML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform HTML into a BeautifulSoup object\n",
    "bs = BeautifulSoup(html.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the content of the page with a nice format\n",
    "print(bs.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the text inside the title tag\n",
    "print(bs.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all instances of the 'p' tag\n",
    "ptag = bs.find_all('p')\n",
    "print(ptag)\n",
    "ptag[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a list of the elements at the top level\n",
    "lst1 = list(bs.children)\n",
    "print(lst1)\n",
    "lst1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of an item\n",
    "[type(item) for item in lst1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all elements inside the html tag\n",
    "lst2 = list(lst1[2].children)\n",
    "lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading weather data\n",
    "page = requests.get('https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168#.XcroLFdKjb0')\n",
    "page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_day = soup.find(id = 'seven-day-forecast') \n",
    "daily_item = seven_day.find_all(class_ = 'tombstone-container')\n",
    "today = daily_item[0]\n",
    "print(today)\n",
    "daily_item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [item.find(class_ = 'period-name').get_text() for item in daily_item]\n",
    "descs = [item.find('img')['title'] for item in daily_item]\n",
    "temps = [item.find(class_ = \"temp\").get_text() for item in daily_item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame({'period': periods, 'description': descs, 'temperature': temps})\n",
    "weather_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
